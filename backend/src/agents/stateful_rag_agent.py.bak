"""
Stateful RAG Agent with Redis + RedisVL memory.

Provides context-aware conversations through dual memory architecture:
- Short-term: Recent conversation history (Redis LIST)
- Long-term: Semantic memory search (RedisVL vector index)
"""

import logging
from dataclasses import dataclass
from typing import Annotated, Any, TypedDict

from langchain_core.messages import SystemMessage, ToolMessage
from langgraph.graph import END, START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

from ..apple_health.query_tools import create_user_bound_tools
from ..utils.agent_helpers import (
    build_base_system_prompt,
    build_error_response,
    build_message_history,
    create_health_llm,
    extract_final_response,
    extract_tool_usage,
    should_continue_tool_loop,
)
from ..utils.numeric_validator import get_numeric_validator
from ..utils.query_classifier import QueryClassifier

logger = logging.getLogger(__name__)


@dataclass
class MemoryContext:
    """Memory retrieval results from Redis and RedisVL."""

    short_term: str | None = None
    long_term: str | None = None
    semantic_hits: int = 0


class StatefulAgentState(TypedDict):
    """LangGraph state for stateful agent workflow."""

    messages: Annotated[list, add_messages]
    user_id: str
    session_id: str
    tool_calls_made: int
    max_tool_calls: int
    short_term_context: str | None
    long_term_context: str | None
    semantic_hits: int


class StatefulRAGAgent:
    """
    RAG agent with Redis-backed memory and intelligent tool routing.

    Architecture:
    - LangGraph workflow with conditional tool execution
    - Query classification for optimized tool selection
    - Dual memory system (Redis + RedisVL)
    - Response validation against tool results

    Memory:
    - Short-term: Conversation history (Redis LIST, 7-month TTL)
    - Long-term: Semantic search (RedisVL HNSW, 1024-dim embeddings)
    """

    def __init__(self, memory_manager):
        """Initialize agent with memory manager and LangGraph workflow."""
        if memory_manager is None:
            raise ValueError(
                "StatefulRAGAgent requires memory_manager. "
                "Use StatelessHealthAgent for no-memory mode."
            )

        self.memory_manager = memory_manager
        self.llm = create_health_llm()
        self.query_classifier = QueryClassifier()

        # Note: No LangGraph checkpointer needed - we use Redis for memory
        # All conversation history is managed by memory_manager

        # Store tools outside state (not serializable)
        self.current_user_tools = []

        self._build_workflow()

        logger.info("StatefulRAGAgent initialized with Redis memory (no LangGraph checkpointer)")

    def _build_workflow(self) -> None:
        """Construct LangGraph workflow with agent-tools loop and checkpointer."""
        workflow = StateGraph(StatefulAgentState)

        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", self._tool_node)

        workflow.add_edge(START, "agent")
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {"continue": "tools", "end": END},
        )
        workflow.add_edge("tools", "agent")

        # Compile without checkpointer - we use Redis for memory persistence
        self.app = workflow.compile()

    async def _agent_node(self, state: StatefulAgentState) -> dict:
        """Agent reasoning node with query classification and memory context."""
        messages = state["messages"]
        user_tools = self.current_user_tools  # Get from instance variable

        current_query = self._extract_current_query(messages)
        classification = self.query_classifier.classify_intent(current_query)

        logger.info(
            f"Query intent: {classification['intent']}, "
            f"confidence: {classification['confidence']:.2f}"
        )

        tools_to_bind = self._filter_tools(user_tools, classification)
        llm_with_tools = self.llm.bind_tools(tools_to_bind)

        system_content = self._build_system_prompt_with_memory(state)
        system_msg = SystemMessage(content=system_content)

        response = await llm_with_tools.ainvoke([system_msg] + messages)

        return {"messages": [response]}

    def _extract_current_query(self, messages: list) -> str:
        """Extract the most recent user message content."""
        for msg in reversed(messages):
            if hasattr(msg, "content") and msg.content:
                return msg.content
        return ""

    def _filter_tools(self, user_tools: list, classification: dict) -> list:
        """Filter tools based on query classification confidence."""
        if self.query_classifier.should_filter_tools(classification, threshold=0.5):
            recommended = set(classification["recommended_tools"])
            filtered = [t for t in user_tools if t.name in recommended]
            logger.info(
                f"Tool filtering: {len(filtered)}/{len(user_tools)} tools "
                f"(confidence {classification['confidence']:.2f})"
            )
            return filtered

        logger.info(
            f"All {len(user_tools)} tools available "
            f"(confidence {classification['confidence']:.2f} below threshold)"
        )
        return user_tools

    def _tool_node(self, state: StatefulAgentState) -> dict:
        """Execute tools selected by agent."""
        return ToolNode(self.current_user_tools).invoke(state)

    def _should_continue(self, state: StatefulAgentState) -> str:
        """Route to tools or end based on agent response."""
        return should_continue_tool_loop(state)

    def _build_system_prompt_with_memory(self, state: StatefulAgentState) -> str:
        """Construct system prompt with memory context injected."""
        prompt_parts = [build_base_system_prompt(), ""]

        prompt_parts.extend(
            [
                "ðŸ§  MEMORY SCOPE:",
                "- 'Earlier today' or 'first question' â†’ Use current conversation",
                "- 'My goals' or 'usually' â†’ Use semantic memory insights",
                "",
                "ðŸ§  MEMORY CONTEXT:",
            ]
        )

        if state.get("short_term_context"):
            prompt_parts.append("Recent conversation:")
            prompt_parts.append(state["short_term_context"])
            prompt_parts.append("")

        if state.get("long_term_context"):
            hits = state.get("semantic_hits", 0)
            prompt_parts.append(f"Semantic memory ({hits} insights):")
            prompt_parts.append(state["long_term_context"])
            prompt_parts.append("")

        return "\n".join(prompt_parts)

    async def _retrieve_memory_context(
        self, user_id: str, session_id: str, message: str
    ) -> MemoryContext:
        """Retrieve dual memory context from Redis and RedisVL."""
        context = MemoryContext()

        try:
            context.short_term = await self.memory_manager.get_short_term_context(
                user_id, session_id
            )
            if context.short_term:
                logger.info(f"Short-term context: {len(context.short_term)} chars")
        except Exception as e:
            logger.warning(f"Short-term retrieval failed: {e}", exc_info=True)
            context.short_term = None

        try:
            result = await self.memory_manager.retrieve_semantic_memory(
                user_id, message, top_k=3
            )
            context.long_term = result.get("context")
            context.semantic_hits = result.get("hits", 0)
            if context.semantic_hits > 0:
                logger.info(f"Semantic memory: {context.semantic_hits} hits")
        except Exception as e:
            logger.warning(f"Semantic retrieval failed: {e}", exc_info=True)
            context.long_term = None
            context.semantic_hits = 0

        return context

    async def _store_memory_interaction(
        self, user_id: str, session_id: str, user_message: str, response_text: str
    ) -> bool:
        """Store meaningful interactions in semantic memory."""
        if len(response_text) <= 50:
            return False

        try:
            await self.memory_manager.store_semantic_memory(
                user_id, session_id, user_message, response_text
            )
            logger.info("Stored in semantic memory")
            return True
        except Exception as e:
            logger.warning(f"Memory storage failed: {e}", exc_info=True)
            return False

    async def chat(
        self,
        message: str,
        user_id: str,
        session_id: str = "default",
        conversation_history: list[dict] | None = None,
        max_tool_calls: int = 5,
    ) -> dict[str, Any]:
        """Process message through RAG pipeline with memory retrieval and storage."""
        try:
            messages = build_message_history(
                conversation_history=conversation_history,
                current_message=message,
                limit=10,
            )

            memory_context = await self._retrieve_memory_context(
                user_id, session_id, message
            )

            # Store tools in instance variable (not serializable, can't be in state)
            self.current_user_tools = create_user_bound_tools(user_id, conversation_history=messages)

            initial_state = {
                "messages": messages,
                "user_id": user_id,
                "session_id": session_id,
                "tool_calls_made": 0,
                "max_tool_calls": max_tool_calls,
                "short_term_context": memory_context.short_term,
                "long_term_context": memory_context.long_term,
                "semantic_hits": memory_context.semantic_hits,
            }

            # Invoke workflow (no thread_id needed - Redis handles persistence)
            final_state = await self.app.ainvoke(initial_state)
            final_messages = final_state["messages"]
            response_text = extract_final_response(final_messages)
            tools_used, tool_count = extract_tool_usage(final_messages)

            validation_result = self._validate_response(final_messages, response_text)

            # Note: Message storage is now handled by RedisChatService
            # Agent only retrieves memory, service layer handles storage
            # Store semantic memory for long-term insights
            await self._store_memory_interaction(
                user_id, session_id, message, response_text
            )

            return self._build_response(
                response_text,
                tools_used,
                tool_count,
                session_id,
                memory_context,
                validation_result,
            )

        except Exception as e:
            return build_error_response(e, "stateful_rag_agent")

    def _validate_response(self, final_messages: list, response_text: str) -> dict:
        """Validate response against tool results for hallucination detection."""
        validator = get_numeric_validator()

        tool_results = [
            {"name": getattr(msg, "name", "unknown"), "content": msg.content}
            for msg in final_messages
            if isinstance(msg, ToolMessage)
        ]

        validation_result = validator.validate_response(
            response_text=response_text,
            tool_results=tool_results,
            strict=False,
        )

        log_level = logger.warning if not validation_result["valid"] else logger.info
        log_level(
            f"Validation {'' if validation_result['valid'] else 'failed '}"
            f"(score: {validation_result['score']:.2%})"
        )

        return validation_result

    def _build_response(
        self,
        response_text: str,
        tools_used: list,
        tool_count: int,
        session_id: str,
        memory_context: MemoryContext,
        validation_result: dict,
    ) -> dict[str, Any]:
        """Construct structured response with memory and validation stats."""
        return {
            "response": response_text,
            "tools_used": tools_used,
            "tool_calls_made": tool_count,
            "session_id": session_id,
            "memory_stats": {
                "short_term_available": memory_context.short_term is not None,
                "semantic_hits": memory_context.semantic_hits,
                "long_term_available": memory_context.long_term is not None,
            },
            "validation": {
                "valid": validation_result["valid"],
                "score": validation_result["score"],
                "hallucinations_detected": len(
                    validation_result.get("hallucinations", [])
                ),
                "numbers_validated": validation_result.get("stats", {}).get(
                    "matched", 0
                ),
                "total_numbers": validation_result.get("stats", {}).get(
                    "total_numbers", 0
                ),
            },
            "type": "stateful_rag_agent",
        }
