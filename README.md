# Redis Wellness ğŸ¥

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![TypeScript](https://img.shields.io/badge/typescript-5.6+-blue.svg)](https://www.typescriptlang.org/)
[![Redis](https://img.shields.io/badge/redis-7.0+-red.svg)](https://redis.io/)
[![FastAPI](https://img.shields.io/badge/fastapi-0.115+-green.svg)](https://fastapi.tiangolo.com/)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)](#-testing)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)
[![Pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit)](https://github.com/pre-commit/pre-commit)
[![Privacy](https://img.shields.io/badge/privacy-100%25%20local-success.svg)](#-privacy--security)

> **Can AI agents be intelligent without memory?** This demo answers that question through a live side-by-side comparison

A **production-ready demo** comparing **stateless chat** vs. **agentic RAG chat** powered by Redis and RedisVL. Experience how memory transforms AI from forgetful to intelligent using **100% local processing** - your health data never leaves your machine.

**Built for Redis interviews and demonstrations** - clean architecture, comprehensive testing, and modern best practices.

## ğŸ¯ The Demo: Stateless vs. Memory-Powered Chat

Watch the same AI agent with and without memory - **the difference is dramatic**.

### Stateless Chat (No Memory)
- âŒ Forgets context immediately after responding
- âŒ Can't answer follow-up questions ("Is that good?")
- âŒ Doesn't understand pronouns ("What was my heart rate during that?")
- âŒ No conversation continuity or personalization
- âŒ Every query starts from scratch

### Redis RAG Chat (Full Memory)
- âœ… **Short-term memory**: Recent conversation history (Redis LIST)
- âœ… **Long-term memory**: Semantic search with vector embeddings (RedisVL HNSW)
- âœ… **Episodic memory**: Personal health events and patterns
- âœ… **Procedural memory**: User preferences and learned behaviors
- âœ… Understands pronouns, references, and follow-up questions
- âœ… Autonomous agentic tool calling with context awareness

## ğŸ—ï¸ Architecture: The Demo Comparison

```mermaid
graph LR
    subgraph Stateless["Stateless Chat - NO MEMORY"]
        SUser[User Query] --> SAgent[Stateless Agent]
        SAgent --> STools[Health Tools]
        STools --> SLLM[Ollama LLM]
        SLLM --> SResponse[Response]
        SResponse -.->|Forgets| SUser
    end

    subgraph RAG["RAG Chat - WITH MEMORY"]
        RUser[User Query] --> RAgent[RAG Agent]
        RAgent --> RMemory[Redis Memory]
        RMemory --> RShort[Short-Term]
        RMemory --> RLong[Long-Term Semantic]
        RAgent --> RTools[Health Tools]
        RTools --> RLLM[Ollama LLM]
        RLLM --> RResponse[Response]
        RResponse --> RMemory
        RResponse -.->|Remembers| RUser
    end

    Redis[(Redis + RedisVL)] --> RMemory
    Ollama[Ollama Host] --> SLLM
    Ollama --> RLLM

    style Stateless fill:#ffebee,stroke:#c62828,stroke-width:3px
    style RAG fill:#e8f5e9,stroke:#2e7d32,stroke-width:3px
    style Redis fill:#dc382d,stroke:#333,stroke-width:2px
    style Ollama fill:#000,stroke:#333,stroke-width:2px
```

### The Key Difference

| | Stateless Chat | RAG Chat |
|---|---|---|
| **Memory** | âŒ None | âœ… Redis + RedisVL |
| **Follow-ups** | âŒ Forgets context | âœ… Remembers conversation |
| **Pronouns** | âŒ "What?" | âœ… Understands "it", "that" |
| **User Goals** | âŒ Lost after query | âœ… Stored semantically |
| **Response** | Generic | Personalized |

## âœ¨ Key Features

### ğŸ¤– Agentic Architecture (Simple Tool Loop)
- **Simple tool-calling loop**: Lightweight, maintainable (replaced LangGraph)
- **9 specialized health tools**: Search, aggregate, workouts, patterns, trends, comparisons
- **Qwen 2.5 7B**: Optimized local LLM for function calling (4.7 GB)
- **Tool-first policy**: Facts from tools, context from memory
- **Autonomous decision-making**: LLM chooses tools and chains operations

### ğŸ§  Dual Memory System (RedisVL)
- **Short-term memory**: Last 10 messages (Redis LIST, 7-month TTL)
- **Long-term semantic memory**: Vector search (RedisVL HNSW index, 1024 dimensions)
- **Episodic memory**: Personal health events with temporal context
- **Procedural memory**: User preferences and interaction patterns
- **Smart retrieval**: Top-3 semantic results per query
- **Vector embeddings**: `mxbai-embed-large` via Ollama (669 MB)

### ğŸ”’ Privacy-First Design
- **100% local processing**: Ollama LLM + Redis + RedisVL on your machine
- **Zero external APIs**: No OpenAI, no cloud dependencies
- **Apple Health integration**: Secure XML parsing with validation
- **Docker isolation**: All services containerized
- **7-month TTL**: Automatic data expiration

## ğŸš€ Quick Start

### Prerequisites

1. **Docker & Docker Compose** - For running all services
2. **Ollama** - For local LLM inference (runs on host)

### Install Ollama & Models

**Why Ollama + Qwen?**
- ğŸ”’ **100% Privacy**: Runs locally, your health data never leaves your machine
- âš¡ **Fast Setup**: One-command install, no API keys or cloud accounts
- ğŸ§  **Smart Tool Calling**: Qwen 2.5 7B excels at function calling for agentic workflows
- ğŸ“Š **Reasonable Size**: 4.7 GB model runs on most modern laptops
- ğŸ¯ **Optimized for Tools**: Better tool selection than larger general-purpose models

```bash
# Install Ollama (macOS)
brew install ollama

# Or download from https://ollama.ai

# Start Ollama service
ollama serve

# In another terminal, pull the models
ollama pull qwen2.5:7b              # Main LLM - optimized for tool calling (4.7 GB)
ollama pull mxbai-embed-large       # Embeddings - for semantic search (669 MB)
```

> **Note**: First run will download models (~5.4 GB total). Subsequent runs are instant.

### Start the Application

**Option 1: Quick start (recommended)**

```bash
chmod +x start.sh
./start.sh
```

This script:
1. Checks Docker and Ollama are running
2. Verifies required models are installed
3. Starts all services with `docker-compose`
4. Opens the UI at http://localhost:3000

**Option 2: Manual start**

```bash
# Build and start all services
docker-compose up --build

# Or run in detached mode
docker-compose up -d --build
```

### Access Points

- **Frontend Demo UI**: http://localhost:3000 (side-by-side chat comparison)
- **Backend API Docs (Swagger)**: http://localhost:8000/docs
- **Backend API Docs (ReDoc)**: http://localhost:8000/redoc
- **RedisInsight**: http://localhost:8001 (visualize Redis data)
- **Health Check**: http://localhost:8000/api/health/check
- **Demo Info**: http://localhost:8000/api/chat/demo/info

## ğŸ“Š Try the Demo

### 1. Load Health Data

Export from Apple Health (or use sample data):

```bash
# Upload your Apple Health export.xml
curl -X POST http://localhost:8000/api/health/upload \
  -F "file=@export.xml"
```

### 2. Compare Stateless vs. RAG Chat

#### Test Scenario: Follow-up Questions

**Stateless Chat** (`POST /api/chat/stateless`):
```
You: "What was my average heart rate last week?"
Bot: "87 bpm"

You: "Is that good?"
Bot: âŒ "What are you referring to?" (forgot context!)
```

**RAG Chat** (`POST /api/chat/redis`):
```
You: "What was my average heart rate last week?"
Bot: "87 bpm"

You: "Is that good?"
Bot: âœ… "87 bpm is within normal range..." (remembers "that" = heart rate!)
```

#### Test Scenario: Pronoun Resolution

**Stateless**:
```
You: "When did I last work out?"
Bot: "2 days ago - Running, 30 minutes"

You: "What was my heart rate during that?"
Bot: âŒ "During what?" (no memory!)
```

**RAG Chat**:
```
You: "When did I last work out?"
Bot: "2 days ago - Running, 30 minutes"

You: "What was my heart rate during that?"
Bot: âœ… "During your run 2 days ago, average was 145 bpm" (remembers context!)
```

### 3. Try Agentic Tool Calling

The RAG agent intelligently selects tools:

```bash
# Aggregation query â†’ calls aggregate_metrics tool
curl -X POST http://localhost:8000/api/chat/redis \
  -H "Content-Type: application/json" \
  -d '{"message": "What was my AVERAGE heart rate last week?"}'

# Retrieval query â†’ calls search_health_records_by_metric tool
curl -X POST http://localhost:8000/api/chat/redis \
  -H "Content-Type: application/json" \
  -d '{"message": "Show me my weight in September"}'

# Workout query â†’ calls search_workouts_and_activity tool
curl -X POST http://localhost:8000/api/chat/redis \
  -H "Content-Type: application/json" \
  -d '{"message": "When did I last work out?"}'
```

## ğŸ§  How Memory Works

### Short-Term Memory (Conversation History)

Recent messages stored in Redis LIST:

```python
conversation:{session_id} â†’ [msg1, msg2, msg3...]
TTL: 7 months
```

- Last 10 messages retrieved for context
- Enables pronoun resolution ("it", "that")
- Maintains conversation flow

### Long-Term Memory (Semantic Search)

Important insights stored in RedisVL vector index:

```python
# Vector embedding stored
memory:{user_id}:{timestamp} â†’ {
    "text": "User's BMI goal is 22",
    "embedding": [0.234, -0.123, ...],  # 1024 dimensions
    "metadata": {...}
}
```

- Semantic search via HNSW index
- Retrieves relevant past conversations
- Powers contextual recall

### Tool Calling with Simple Loop

1. **Query Analysis**: LLM understands intent autonomously
2. **Tool Selection**: Qwen 2.5 7B chooses optimal tools natively
3. **Tool Execution**: Simple loop (up to 8 iterations) for multi-step workflows
4. **Memory Update**: Store results in CoALA memory (episodic, procedural, semantic, short-term)

## ğŸ”§ Project Structure

**Production-ready architecture with clean separation of concerns:**

```
.
â”œâ”€â”€ backend/                         # FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agents/                  # AI agents (simple tool loop)
â”‚   â”‚   â”‚   â”œâ”€â”€ stateless_agent.py   # Baseline agent (NO memory)
â”‚   â”‚   â”‚   â”œâ”€â”€ stateful_rag_agent.py # Redis RAG agent (FULL memory)
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ apple_health/            # Apple Health data processing
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py            # Pydantic models (HealthRecord, Workout)
â”‚   â”‚   â”‚   â”œâ”€â”€ parser.py            # Secure XML parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ query_tools/         # 9 LangChain tools for AI queries
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ services/                # Data layer & business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_chat.py        # RAG chat with dual memory
â”‚   â”‚   â”‚   â”œâ”€â”€ stateless_chat.py    # Baseline (no memory)
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_manager.py    # RedisVL dual memory system
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_connection.py  # Redis connection management
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_workout_indexer.py # Fast Redis indexes
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_apple_health_manager.py # Health CRUD
â”‚   â”‚   â”‚   â””â”€â”€ embedding_cache.py   # Embedding performance cache
â”‚   â”‚   â”œâ”€â”€ utils/                   # Pure utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_helpers.py     # Shared agent utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ numeric_validator.py # Anti-hallucination validation
â”‚   â”‚   â”‚   â”œâ”€â”€ workout_fetchers.py  # Workout data utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ metric_aggregators.py # Health metric aggregation
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py              # Base classes & decorators
â”‚   â”‚   â”‚   â”œâ”€â”€ stats_utils.py       # Statistical calculations
â”‚   â”‚   â”‚   â”œâ”€â”€ time_utils.py        # Time parsing
â”‚   â”‚   â”‚   â””â”€â”€ health_analytics.py  # Trend analysis
â”‚   â”‚   â”œâ”€â”€ api/                     # HTTP endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_routes.py       # Demo chat endpoints
â”‚   â”‚   â”‚   â””â”€â”€ system_routes.py     # Health & system routes
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI app
â”‚   â”‚   â””â”€â”€ config.py                # Settings
â”‚   â”œâ”€â”€ tests/                       # Comprehensive test suite
â”‚   â”‚   â”œâ”€â”€ unit/                    # Unit tests (no dependencies)
â”‚   â”‚   â”œâ”€â”€ test_redis_chat_rag.py   # RAG memory tests
â”‚   â”‚   â””â”€â”€ test_redis_chat_api.py   # API integration tests
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml               # uv dependencies
â”‚
â”œâ”€â”€ frontend/                        # TypeScript + Vite UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.ts                  # Side-by-side chat UI
â”‚   â”‚   â”œâ”€â”€ api.ts                   # Backend API client
â”‚   â”‚   â”œâ”€â”€ streaming.ts             # SSE streaming handlers
â”‚   â”‚   â”œâ”€â”€ stats.ts                 # Performance stats tracking
â”‚   â”‚   â”œâ”€â”€ types.ts                 # TypeScript interfaces
â”‚   â”‚   â”œâ”€â”€ constants.ts             # App constants
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ sanitizer.ts         # XSS protection
â”‚   â”‚   â”‚   â””â”€â”€ ui.ts                # UI utilities
â”‚   â”‚   â””â”€â”€ style.css                # Modern glassmorphism UI
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ Dockerfile                   # Nginx production build
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ docs/                            # Technical documentation
â”‚   â”œâ”€â”€ HEALTH_DATA_PIPELINE.md      # Apple Health â†’ Redis
â”‚   â”œâ”€â”€ LANGGRAPH_REMOVAL_PLAN.md    # Why simple loop > LangGraph
â”‚   â”œâ”€â”€ INTELLIGENT_HEALTH_TOOLS_PLAN.md
â”‚   â”œâ”€â”€ RAG_IMPLEMENTATION.md        # RedisVL memory architecture
â”‚   â””â”€â”€ linting.md                   # Code quality setup
â”‚
â”œâ”€â”€ import_health_data.py            # Apple Health import script
â”œâ”€â”€ docker-compose.yml               # Full stack orchestration
â”œâ”€â”€ start.sh                         # Quick start script
â”œâ”€â”€ lint.sh                          # Run all linters
â””â”€â”€ WARP.md                          # Development guidance for AI
```

**Key Architecture Decisions:**
- **Simple tool loop** instead of LangGraph (lighter, easier to debug)
- **Apple Health module** consolidates all health data processing
- **Services layer** handles Redis, memory, and business logic
- **Utils** contains only pure functions (no side effects)
- **Tests** in `/backend/tests/` for proper monorepo structure

## ğŸ“š API Endpoints

### Core Demo Endpoints

**Chat Comparison:**
- `POST /api/chat/stateless/stream` - Stateless chat with SSE streaming (no memory)
- `POST /api/chat/redis/stream` - Redis RAG chat with SSE streaming (full memory)
- `POST /api/chat/stateless` - Stateless chat (JSON response)
- `POST /api/chat/redis` - Redis RAG chat (JSON response)

**Session Management:**
- `GET /api/chat/history/{session_id}` - View conversation history
- `GET /api/chat/memory/{session_id}` - Memory statistics and usage
- `DELETE /api/chat/session/{session_id}` - Clear session data

**System Health:**
- `GET /api/health/check` - Redis, Ollama, and system status
- `GET /api/chat/demo/info` - Complete demo documentation

### Example: Streaming Chat Request

```bash
# Stateless chat (forgets context)
curl -X POST http://localhost:8000/api/chat/stateless/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "What was my average heart rate last week?"}'

# Redis RAG chat (remembers context)
curl -X POST http://localhost:8000/api/chat/redis/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "What was my average heart rate last week?", "session_id": "demo-session"}'
```

### Response Format

**Streaming (SSE):**
```
data: {"type": "token", "content": "Your "}
data: {"type": "token", "content": "average "}
data: {"type": "done", "data": {"response": "...", "tools_used": [...], "memory_stats": {...}}}
```

**JSON Response:**
```json
{
  "response": "Your average heart rate last week was 87 bpm.",
  "session_id": "demo-session",
  "tools_used": [{"name": "aggregate_metrics", "args": {...}}],
  "tool_calls_made": 1,
  "memory_stats": {
    "semantic_hits": 2,
    "short_term_available": true,
    "memory_types": ["episodic", "semantic"]
  },
  "response_time_ms": 3421
}
```

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose | Details |
|-----------|-----------|---------|----------|
| **Agent Framework** | Simple Tool Loop | Lightweight agentic workflow | Replaced LangGraph for simplicity |
| **LLM** | Qwen 2.5 7B (Ollama) | Local tool calling | 4.7 GB, optimized for functions |
| **Embeddings** | mxbai-embed-large (Ollama) | Semantic vectors | 669 MB, 1024 dimensions |
| **Short-term Memory** | Redis LIST | Conversation history | Last 10 messages, 7-month TTL |
| **Long-term Memory** | RedisVL HNSW | Semantic search | Vector index, top-3 retrieval |
| **Backend** | FastAPI 0.115+ | Async Python API | SSE streaming, CORS middleware |
| **Frontend** | TypeScript 5.6 + Vite | Modern React-less UI | XSS protection, glassmorphism |
| **Package Manager** | uv (backend) + npm (frontend) | Fast dependency management | Rust-based Python package manager |
| **Orchestration** | Docker Compose | Full stack deployment | 4 services: frontend, backend, redis, redis-insight |
| **Code Quality** | Ruff + ESLint + Prettier | Linting & formatting | Pre-commit hooks enabled |

## ğŸ”’ Privacy & Security

- **100% local processing**: Ollama runs on your machine
- **No external APIs**: Zero data sent to cloud services
- **Your data, your control**: Redis runs locally
- **7-month TTL**: Automatic data expiration
- **Apple Health privacy**: Import your own data securely

## ğŸ§ª Testing

**Comprehensive test suite** with anti-hallucination strategies and 100% structure validation.

### Quick Start

```bash
cd backend

# Run all tests
uv run pytest tests/ -v

# Unit tests only (fast, no dependencies)
uv run pytest tests/unit/ -v

# Integration tests (require Redis)
uv run pytest tests/ -k "not unit" -v

# With coverage report
uv run pytest --cov=src --cov-report=html tests/
```

### Test Categories

**Unit Tests** - Pure functions, no external dependencies
- `test_numeric_validator.py` - LLM hallucination detection (24 tests)
- `test_stats_utils.py` - Statistical calculations (29 tests)
- `test_stateless_isolation.py` - Pure function validation
- **Fast**: Runs in <0.5s

**Integration Tests** - Redis operations
- `test_redis_chat_rag.py` - Dual memory system (episodic, semantic, procedural)
- `test_redis_chat_api.py` - HTTP endpoints and streaming
- `test_memory_manager.py` - RedisVL vector operations
- **Requires**: Redis + Ollama running

**Agent Tests** - LLM behavior validation
- Structural validation (fields, types, tool selection)
- Response validity (numbers match tool results)
- Semantic validation (keywords, no errors)
- **No exact text matching** (LLMs are non-deterministic)

### Anti-Hallucination Strategy

**âœ… What We Test:**
```python
# Structure validation
assert "response" in result
assert isinstance(result["tools_used"], list)

# Validity checks
assert tool_result == numeric_in_response  # No hallucinated numbers
assert "error" not in response.lower()     # No error messages

# Semantic validation
assert "heart rate" in response.lower()    # Expected keywords
```

**âŒ What We DON'T Test:**
- Exact LLM wording ("Your average heart rate was..." vs "You averaged...")
- Creative phrasing or tone
- Response length or formatting details

### Running Specific Tests

```bash
# Numeric validation tests
uv run pytest tests/unit/test_numeric_validator.py -v

# RAG memory tests
uv run pytest tests/test_redis_chat_rag.py -v

# API streaming tests
uv run pytest tests/test_redis_chat_api.py::test_streaming_response -v
```

### Code Quality

```bash
# Run all linters (Ruff + Prettier + ESLint)
./lint.sh

# Backend only (Python)
cd backend
uv run ruff check --fix src tests
uv run ruff format src tests

# Frontend only (TypeScript)
cd frontend
npm run lint        # ESLint + Prettier
npm run typecheck   # TypeScript compiler
```

## ğŸ“š Documentation & Resources

### Project Documentation

**Architecture & Design:**
- [WARP.md](./WARP.md) - Complete development guide (for AI assistants)
- [HEALTH_DATA_PIPELINE.md](./docs/HEALTH_DATA_PIPELINE.md) - Apple Health â†’ Redis pipeline
- [LANGGRAPH_REMOVAL_PLAN.md](./docs/LANGGRAPH_REMOVAL_PLAN.md) - Why simple loop > LangGraph
- [RAG_IMPLEMENTATION.md](./docs/RAG_IMPLEMENTATION.md) - RedisVL memory architecture
- [INTELLIGENT_HEALTH_TOOLS_PLAN.md](./docs/INTELLIGENT_HEALTH_TOOLS_PLAN.md) - Agentic tools design

**Development:**
- [linting.md](./docs/linting.md) - Code quality setup & pre-commit hooks
- [TEST_PLAN.md](./backend/TEST_PLAN.md) - Comprehensive testing strategy
- [tests/README.md](./backend/tests/README.md) - Running tests

### External Resources

**Core Technologies:**
- [Redis Stack](https://redis.io/docs/stack/) - In-memory data store
- [RedisVL](https://redisvl.com) - Vector library for Redis
- [Ollama](https://ollama.ai) - Local LLM runtime
- [Qwen 2.5](https://qwenlm.github.io/) - Function-calling LLM
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework

**Developer Tools:**
- [uv](https://github.com/astral-sh/uv) - Fast Python package manager
- [Ruff](https://docs.astral.sh/ruff/) - Python linter & formatter
- [Vite](https://vitejs.dev/) - Frontend build tool

## ğŸ› Troubleshooting

### Services Not Starting

```bash
# Check Docker is running
docker info
docker ps

# View all logs
docker-compose logs -f

# View specific service
docker-compose logs -f backend
docker-compose logs -f frontend

# Restart specific service
docker-compose restart backend

# Rebuild after code changes
docker-compose build backend
docker-compose up -d backend
```

### Ollama Issues

```bash
# Check if Ollama is running
curl http://localhost:11434/api/version

# Check installed models
ollama list

# Pull missing models
ollama pull qwen2.5:7b              # 4.7 GB
ollama pull mxbai-embed-large       # 669 MB

# Restart Ollama service
pkill ollama && ollama serve
```

### Redis Connection Issues

```bash
# Check Redis is running
docker-compose ps redis

# Test Redis connection
redis-cli -h localhost -p 6379 ping
# Expected: PONG

# View Redis data
redis-cli
> KEYS conversation:*
> KEYS memory:*

# Clear all Redis data (caution!)
redis-cli FLUSHALL
```

### Frontend Not Loading

```bash
# Check frontend logs
docker-compose logs frontend

# Check if frontend is running
curl http://localhost:3000

# Rebuild frontend
docker-compose build frontend
docker-compose up -d frontend
```

### Tool Calling Not Working

```bash
# Check backend logs for tool execution
docker-compose logs backend | grep "tool"

# Check health data is loaded
curl http://localhost:8000/api/health/check

# Test tools directly
curl -X POST http://localhost:8000/api/chat/redis \
  -H "Content-Type: application/json" \
  -d '{"message": "What was my heart rate yesterday?", "session_id": "test"}'
```

### Port Conflicts

```bash
# Check what's using ports
lsof -i :3000  # Frontend
lsof -i :8000  # Backend
lsof -i :6379  # Redis
lsof -i :11434 # Ollama

# Kill process on port
lsof -ti:8000 | xargs kill -9
```

### Memory/Performance Issues

```bash
# Check Docker resource usage
docker stats

# Check Ollama GPU usage (if available)
ollama ps

# Reduce memory usage: use smaller model
ollama pull qwen2.5:3b  # Smaller alternative (2.0 GB)
```

## ğŸ¤ Contributing

This is a **demonstration project** built for Redis interviews and technical presentations.

**Ways to Contribute:**
- ğŸ› Report bugs or issues
- ğŸ’¡ Suggest improvements or new features
- ğŸ“ Improve documentation
- â­ Star the repo if you find it useful!
- ğŸ‘¥ Share with others learning Redis + AI

**For Redis Employees:**
This project demonstrates best practices for:
- RedisVL vector search
- Dual memory architecture (short-term + long-term)
- Production-ready FastAPI + Redis integration
- Local-first AI with Ollama
- Comprehensive testing strategies

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ¯ Why This Project Exists

**The Question:** Can AI agents be intelligent without memory?

**The Answer:** Watch the side-by-side demo and decide for yourself.

This project proves that memory â€” powered by Redis and RedisVL â€” transforms AI from forgetful chatbots into intelligent, context-aware assistants.

**Built for:**
- ğŸ‘¥ Redis technical interviews & demonstrations
- ğŸ« Learning Redis + RedisVL + RAG architecture
- ğŸ”’ Privacy-conscious AI applications (100% local)
- ğŸ§ª Testing agentic workflows with real health data

---

<p align="center">
  <strong>Built with â¤ï¸ by <a href="https://github.com/AllieRays">@AllieRays</a></strong><br>
  <em>Demonstrating why memory matters in AI conversations</em>
</p>

<p align="center">
  <strong>Tech Stack:</strong> Redis â€¢ RedisVL â€¢ Ollama â€¢ FastAPI â€¢ TypeScript â€¢ Docker
</p>
